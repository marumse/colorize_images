\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{Zhang.2016}
\citation{jia2014caffe}
\citation{Zhang.2016}
\citation{Zhang.2016}
\citation{Levin.2004}
\citation{Cheng_2015}
\citation{Zhang.2016}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theoretical Background}{3}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Related work}{3}{subsection.2.1}}
\citation{Hubel1962}
\citation{Escontrela.2018}
\citation{Escontrela.2018}
\citation{Lecture.2019}
\citation{Russakovsky.2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Convolutional neural networks for image colorization}{4}{subsection.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Convolutional operation: kernel slides over the input, multiplying it with its weight before summarizing the 3x3 neighborhood \citep  {Escontrela.2018}.\relax }}{4}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{convolut}{{1}{4}{Convolutional operation: kernel slides over the input, multiplying it with its weight before summarizing the 3x3 neighborhood \citep {Escontrela.2018}.\relax }{figure.caption.2}{}}
\citation{Russakovsky.2014}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Guiding Paper}{5}{subsection.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example results from different approaches tested by Zhang et al. (2016)\relax }}{5}{figure.caption.3}}
\newlabel{zhangpred}{{2}{5}{Example results from different approaches tested by Zhang et al. (2016)\relax }{figure.caption.3}{}}
\citation{Zhang.2016}
\citation{cantor2007}
\@writefile{toc}{\contentsline {section}{\numberline {3}Network Structure and Implementation}{6}{section.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The network architecture of Zhang et al. (2016). \relax }}{6}{figure.caption.4}}
\newlabel{network}{{3}{6}{The network architecture of Zhang et al. (2016). \relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data Generation}{6}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The data generator creates batches of input and target tupels.\relax }}{7}{figure.caption.5}}
\newlabel{datagen}{{4}{7}{The data generator creates batches of input and target tupels.\relax }{figure.caption.5}{}}
\citation{Lecture.2019}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Implementation of the Cantor Pairing Function.\relax }}{8}{figure.caption.6}}
\newlabel{cantorpairing}{{5}{8}{Implementation of the Cantor Pairing Function.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Implementation of the one-hot encoding.\relax }}{8}{figure.caption.7}}
\newlabel{onehot}{{6}{8}{Implementation of the one-hot encoding.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model Structure}{8}{subsection.3.2}}
\citation{Glorot2010}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Training}{9}{subsection.3.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Testing}{10}{subsection.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{10}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Classical Approach}{10}{subsection.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Example ground truth images from the ImageNet test set, with corresponding extracted L-input layer and prediction by our classical approach.\relax }}{11}{figure.caption.8}}
\newlabel{classical}{{7}{11}{Example ground truth images from the ImageNet test set, with corresponding extracted L-input layer and prediction by our classical approach.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces History of the MSE loss: The loss is evaluated after each epoch, for a period of 50 epochs.\relax }}{11}{figure.caption.9}}
\newlabel{loss_class}{{8}{11}{History of the MSE loss: The loss is evaluated after each epoch, for a period of 50 epochs.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Classification Approach}{12}{subsection.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Example ground truth images from the ImageNet test set, with corresponding extracted L-input layer and prediction by our classification approach.\relax }}{12}{figure.caption.10}}
\newlabel{classificatio}{{9}{12}{Example ground truth images from the ImageNet test set, with corresponding extracted L-input layer and prediction by our classification approach.\relax }{figure.caption.10}{}}
\citation{Zhang.2016}
\citation{Zhang.2016}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{13}{section.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Closeup to the colored dots in the prediction of the classification model.\relax }}{13}{figure.caption.11}}
\newlabel{dots}{{10}{13}{Closeup to the colored dots in the prediction of the classification model.\relax }{figure.caption.11}{}}
\citation{Zhang.2016}
\citation{Zhang.2016}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{14}{section.6}}
\bibstyle{apa}
\bibdata{lit}
\bibcite{Cheng_2015}{{1}{2015}{{Cheng et~al.}}{{}}}
\bibcite{Lecture.2019}{{2}{2019}{{Effenberger}}{{}}}
\bibcite{Escontrela.2018}{{3}{2018}{{Escontrela}}{{}}}
\bibcite{Glorot2010}{{4}{2010}{{Glorot and Bengio}}{{}}}
\bibcite{Hubel1962}{{5}{1962}{{Hubel and Wiesel}}{{}}}
\bibcite{jia2014caffe}{{6}{2014}{{Jia et~al.}}{{}}}
\bibcite{Levin.2004}{{7}{2004}{{Levin et~al.}}{{}}}
\bibcite{cantor2007}{{8}{2007}{{Meri}}{{}}}
\bibcite{Russakovsky.2014}{{9}{2014}{{Russakovsky et~al.}}{{}}}
\bibcite{Zhang.2016}{{10}{2016}{{Zhang et~al.}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Literature}{15}{section.7}}
\newlabel{Lit}{{7}{15}{Literature}{section.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Error Message}{16}{appendix.A}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Error message that occurs during running the classification model on the university server.\relax }}{16}{figure.caption.12}}
\newlabel{error}{{11}{16}{Error message that occurs during running the classification model on the university server.\relax }{figure.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Layers of the Model}{17}{appendix.B}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Model summary of the implemented CNN, giving detailed information about the different layers, the output shape and the number of parameters.\relax }}{17}{figure.caption.13}}
\newlabel{modellayer}{{12}{17}{Model summary of the implemented CNN, giving detailed information about the different layers, the output shape and the number of parameters.\relax }{figure.caption.13}{}}
