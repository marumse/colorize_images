Project Guidline:

Paper: https://arxiv.org/abs/1603.08511
- we will only look at their best resulte
- classes sind farbwerte
- 10x10 große bins: gucke wie oft die einzelnen farbwerte in dem bins vorkommen
-> das benutzen um zu reweighten

1. Dataset suchen (mehrere Vorschläge willkommen)
-> cifar(zu wenig klassen), und verschiedene Varianten von imagenet auf dem
  Server
-> im paper PASCAL dataset (http://host.robots.ox.ac.uk/pascal/VOC/)
  und Imagenet
-> Pascal: 20 classes. The train/val data has 11,530 images containing 27,450
  ROI annotated objects and 6,929 segmentation.
  Datasets for classification, detection and person layout are
  the same as VOC2011.
-> vergleich mit SUN dataset (https://groups.csail.mit.edu/vision/SUN/)
-> SUN: large variety of environmental scenes, places and the objects within
  SUN2012: 16,873 images, Also available in PASCAL format (ist das also nur ein format?)
- "Though our model was trained on object-centric ImageNet dataset, we demonstrate
that it nonetheless remains effective for photos from the scene-centric SUN dataset" (p. 23)

2. Bilder in lab und greyscale
2.1 große Mengen an Bildern (1 Mio) handeln (lade problem?)
- skript, dass das datenset generiert (1000 bilder pro 1000 klassen ist zu groß)
- ziel mindestens 100.000
- als numpy oder image date?

2.2 kleineres datenset zum debuggen etc erstellen - selbe klasse 100 bilder
Z:\net\projects\scratch\winter\valid_until_31_July_2020\asparagus\LabelFiles\colorize_images

2.2 preprocessing: cropping, labspace umwandeln (statt RGB) - sophia
- in lab space umwandeln: mit cv2, angelehnt an diese Funktion: https://medium.com/@halmubarak/changing-color-space-hsv-lab-while-reading-from-directory-in-keras-c8ca243e2d57
- labspace ist ein colorspace, luminanca und dann farbe encoden
-> d.h. erste layer ist greyscale, channel ab ist target


2.3. trenne datenset in l und ab
- cropping of L und ab mit dieser Funktion tf.unstack(lab, axis=2) https://github.com/xahidbuffon/rgb-lab-conv/blob/master/rgb_lab_formulation.py 

2.4 loss function schreiben (caffe) - from original paper versuchen anzupassen? - malin
- annealed mean?
- reweightender einzelnen bins

3. lege report als texfile an (maren)

4. layer nachbauen
- do we use keras, tf1 or tf2(with keras), how can we use what code?
  blogpost on difference: https://www.pyimagesearch.com/2019/10/21/keras-vs-tf-keras-whats-the-difference-in-tensorflow-2-0/
  some info found in this book:  (specifically p.109 and surrounding ones for model and keras writing for preprocessing of dataGenerator) https://books.google.de/books?id=l86PDwAAQBAJ&pg=PA109&lpg=PA109&dq=keras.preprocessing.image.ImageDataGenerator(featurewise_center%3DFalse,+samplewise_center%3DFalse,+featurewise_std_normalization%3DFalse,+samplewise_std_normalization%3DFalse,+zca_whitening%3DFalse,+zca_epsilon%3D1e-06,+rotation_range%3D0,+width_shift_range%3D0.0,+height_shift_range%3D0.0,+brightness_range%3DNone,+shear_range%3D0.0,+zoom_range%3D0.0,+channel_shift_range%3D0.0,+fill_mode%3D%27nearest%27,+cval%3D0.0,+horizontal_flip%3DFalse,+vertical_flip%3DFalse,+rescale%3DNone,+preprocessing_function%3DNone,+data_format%3D%27channels_last%27,+validation_split%3D0.0,+interpolation_order%3D1,+dtype%3D%27float32%27)+in+tf+2.0&source=bl&ots=4PaPUc1vta&sig=ACfU3U2jvCN8UW4dirz_NtwMcQGAq4Gugg&hl=de&sa=X&ved=2ahUKEwjyx4n10tHnAhXCfZoKHfAjBikQ6AEwAXoECAoQAQ#v=onepage&q=keras.preprocessing.image.ImageDataGenerator(featurewise_center%3DFalse%2C%20samplewise_center%3DFalse%2C%20featurewise_std_normalization%3DFalse%2C%20samplewise_std_normalization%3DFalse%2C%20zca_whitening%3DFalse%2C%20zca_epsilon%3D1e-06%2C%20rotation_range%3D0%2C%20width_shift_range%3D0.0%2C%20height_shift_range%3D0.0%2C%20brightness_range%3DNone%2C%20shear_range%3D0.0%2C%20zoom_range%3D0.0%2C%20channel_shift_range%3D0.0%2C%20fill_mode%3D'nearest'%2C%20cval%3D0.0%2C%20horizontal_flip%3DFalse%2C%20vertical_flip%3DFalse%2C%20rescale%3DNone%2C%20preprocessing_function%3DNone%2C%20data_format%3D'channels_last'%2C%20validation_split%3D0.0%2C%20interpolation_order%3D1%2C%20dtype%3D'float32')%20in%20tf%202.0&f=false
- conv layer same padding in tensorflow und in dem model ist pad: 1 steht und in caffe
-> für conv layer 5 und 6 benutzten die caffe pad: 2: um das umzusetzen müssten wir eine neue pad funktion schreiben
daher weichen wir erstmal vom code ab, falls das nicht funktioniert (hier in irgendeinem ordner https://github.com/richzhang/colorization/blob/master/interactive-deep-colorization/data/lab_gamut.py)


5. training

6. exp.

7. visualisierung der results

8. Blogpost fertig schreiben

##########################################################################################################

REPORT:
1. Introduction/Motivation
- we want to built a network that can colorize images
- we want to built a network that can colorize images\\
- this project aims to produce colorful images, given a greyscale picture.\\
- transforming greyscale into plausible colors is an easy task for humans\\
- We see a greyscale picture showing a woman playing volleyball at the beach. As we can recognize the scene and the form and relate to it. The sand is yellow, the sea is blue and the ball is white.\\
- But coloring it in life would be a much more difficult task. As we also need to consider different textures, shades and so on. Seeing and imagining things does not make people a proper painter.\\
- Surface structure and the semantics of the scene are necessary to validly color images.\\
- this project aims does not aim to generate the true color for pictures but at least a good and prediction.\\
- aus dem paper: model enough of the statistical dependencies between semantics and the textures of greyscale images and their color versions in order to produce visually compelling results.\\

2. Important background knowledge (including reference to most relevant publications)
- We started looking at this paper:
https://arxiv.org/abs/1603.08511
- at their best solution

3. The model and the experiment (MAIN PART). This part should feature code.

3.1 Dataset
- loading large amount of data
https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/
- we decided to take Imagenet as we have it on the IKW server and it provides a lot of images

3.2 Preprocessing
- image preprocessing documentation
https://keras.io/preprocessing/image/#imagedatagenerator-class

3.3 Layer

3.4 Loss-Function

4. Visualization and discussion of your results.

4.1 Training

4.2 Testing
